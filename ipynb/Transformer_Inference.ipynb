{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer Inference",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EddyDavies/Trade_With_Twitter/blob/main/ipynb/Transformer_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpL2eUlTTzPn",
        "outputId": "dbc4d6b4-94fc-46ad-ae4c-c6f95c05fcf0"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    drive.mount('/content/drive')\n",
        "except ModuleNotFoundError:\n",
        "    IN_COLAB = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv9p46T-cNTU"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mglHXkp5lJJT"
      },
      "source": [
        "Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOuq2MqzlRPG",
        "outputId": "fc3efe13-6910-4753-f9ee-c7733e2b411f"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 14 10:51:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssZFeZ-wlbM9"
      },
      "source": [
        "Check TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybKB8RWgld3-"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf-u-YRelOxj"
      },
      "source": [
        "Check Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1_tNatVlHk1",
        "outputId": "63efec3a-dc4e-485f-9f47-f806b596dc39"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JQMNNgb3ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7acd0e8-d73e-4b0e-cccc-582557af5588"
      },
      "source": [
        "!git clone https://github.com/EddyDavies/Trade_With_Twitter.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Trade_With_Twitter'...\n",
            "remote: Enumerating objects: 525, done.\u001b[K\n",
            "remote: Counting objects: 100% (525/525), done.\u001b[K\n",
            "remote: Compressing objects: 100% (375/375), done.\u001b[K\n",
            "remote: Total 525 (delta 301), reused 317 (delta 142), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (525/525), 153.47 KiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (301/301), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpKovQEbHkgm",
        "outputId": "d1881d8a-32f2-4818-cd1c-4fe24e8df54d"
      },
      "source": [
        "!ls ../"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t datalab  home\t lib64\topt\t    root  srv\t\t     tmp    var\n",
            "boot\t dev\t  lib\t media\tproc\t    run   sys\t\t     tools\n",
            "content  etc\t  lib32  mnt\tpython-apt  sbin  tensorflow-1.15.2  usr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2coR1uRMHkbc",
        "outputId": "68b9f8e3-5006-43f1-d531-46af210181c9"
      },
      "source": [
        "%cd Trade_With_Twitter/src\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Trade_With_Twitter/src\n",
            "bert_farm.ipynb  decorators.py\tsentiment  utils.py\n",
            "bert_farm.py\t prices\t\ttwitter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvQ9fTwdr2QH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e0b164-fbe8-45eb-d94e-cced5588a4a5"
      },
      "source": [
        "!pip install -r ../requirements.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 6)) (1.1.5)\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 19)) (4.62.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r ../requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r ../requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->-r ../requirements.txt (line 6)) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r ../requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]->-r ../requirements.txt (line 7)) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[torch]->-r ../requirements.txt (line 7)) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[torch]->-r ../requirements.txt (line 7)) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[torch]->-r ../requirements.txt (line 7)) (21.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[torch]->-r ../requirements.txt (line 7)) (4.6.4)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]->-r ../requirements.txt (line 7)) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers[torch]->-r ../requirements.txt (line 7)) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[torch]->-r ../requirements.txt (line 7)) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[torch]->-r ../requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]->-r ../requirements.txt (line 7)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]->-r ../requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]->-r ../requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]->-r ../requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[torch]->-r ../requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[torch]->-r ../requirements.txt (line 7)) (1.0.1)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=e768bb8558551fb39eb16ac376e19504787bae322b777230ab03f7334786083f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n",
            "Successfully built emoji\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, emoji\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed emoji-1.4.2 huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5ii2NiXAUZF"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import get_date_array, get_month_array\n",
        "from sentiment.inference import get_paths, get_tweets, get_sentiments, save_sentiments\n",
        "from utils import get_date_array, get_month_array, check_last_day"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD1CfxrbBfxf"
      },
      "source": [
        "# 10% before \"2017-09-19\" and 30% after\n",
        "# dates_range = (\"2017-01-01\", \"2021-06-20\")\n",
        "# dates_range = (\"2017-09-19\", \"2021-06-20\")\n",
        "# dates_range = (\"2018-01-12\", \"2021-06-20\")\n",
        "# 100% after \"2018-03-19\"\n",
        "# dates_range = (\"2018-03-19\", \"2021-06-20\")\n",
        "dates_range = (\"2018-06-29\", \"2021-06-20\")\n",
        "months_range = [\"Jan 17\", \"Jun 21\"]\n",
        "\n",
        "months = get_month_array(months_range)\n",
        "dates = get_date_array(dates_range)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAUgIFIPpoA5"
      },
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "# model = model.to('cuda:0')\n",
        "\n",
        "# sentiment_analysis = pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\", model=model_name, device=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEk0jbduPfW_"
      },
      "source": [
        "if IN_COLAB:\n",
        "    source, results_folder = get_paths(data_folder='../../drive/MyDrive/ColabData', model_name=model_name)\n",
        "else:\n",
        "    source, results_folder = get_paths()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CPgRTRM_IKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befc4f04-5bfd-48ca-e9ac-6a79f7b0c70d"
      },
      "source": [
        "for date in dates:\n",
        "    ids, tweets = get_tweets(date, source)\n",
        "\n",
        "    percentage_per_chunk = 100\n",
        "    save_every = 20000\n",
        "    results = get_sentiments(date, tweets, ids, results_folder,\n",
        "                              sentiment_analysis=sentiment_analysis,\n",
        "                              save_every=save_every,\n",
        "                              percentage_per_chunk=percentage_per_chunk,\n",
        "                             slice_size=None,\n",
        "                             batch_size=100)\n",
        "\n",
        "    # check_last_day(results_folder, date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-03-19: 100%|██████████| 356/356 [01:05<00:00,  5.42it/s]\n",
            "2018-03-20: 100%|██████████| 326/326 [01:01<00:00,  5.31it/s]\n",
            "2018-03-21: 100%|██████████| 326/326 [01:01<00:00,  5.30it/s]\n",
            "2018-03-22: 100%|██████████| 326/326 [01:01<00:00,  5.30it/s]\n",
            "2018-03-23: 100%|██████████| 326/326 [01:01<00:00,  5.31it/s]\n",
            "2018-03-24: 100%|██████████| 326/326 [01:01<00:00,  5.31it/s]\n",
            "2018-03-25: 100%|██████████| 326/326 [01:01<00:00,  5.31it/s]\n",
            "2018-03-26: 100%|██████████| 326/326 [01:01<00:00,  5.29it/s]\n",
            "2018-03-27: 100%|██████████| 326/326 [01:01<00:00,  5.31it/s]\n",
            "2018-03-28: 100%|██████████| 326/326 [01:01<00:00,  5.31it/s]\n",
            "2018-03-29: 100%|██████████| 326/326 [01:01<00:00,  5.31it/s]\n",
            "2018-03-30: 100%|██████████| 62/62 [00:11<00:00,  5.34it/s]\n",
            "2018-03-31: 100%|██████████| 62/62 [00:11<00:00,  5.34it/s]\n",
            "2018-04-01: 100%|██████████| 271/271 [00:50<00:00,  5.35it/s]\n",
            "2018-04-02: 100%|██████████| 271/271 [00:50<00:00,  5.32it/s]\n",
            "2018-04-03: 100%|██████████| 271/271 [00:50<00:00,  5.33it/s]\n",
            "2018-04-04: 100%|██████████| 271/271 [00:50<00:00,  5.34it/s]\n",
            "2018-04-05: 100%|██████████| 271/271 [00:50<00:00,  5.35it/s]\n",
            "2018-04-06: 100%|██████████| 271/271 [00:50<00:00,  5.35it/s]\n",
            "2018-04-07: 100%|██████████| 271/271 [00:50<00:00,  5.33it/s]\n",
            "2018-04-08: 100%|██████████| 271/271 [00:50<00:00,  5.35it/s]\n",
            "2018-04-09: 100%|██████████| 271/271 [00:50<00:00,  5.35it/s]\n",
            "2018-04-10: 100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n",
            "2018-04-11: 100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n",
            "2018-04-12: 100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n",
            "2018-04-13: 100%|██████████| 323/323 [01:01<00:00,  5.28it/s]\n",
            "2018-04-14: 100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n",
            "2018-04-15: 100%|██████████| 323/323 [01:01<00:00,  5.28it/s]\n",
            "2018-04-16: 100%|██████████| 323/323 [01:01<00:00,  5.28it/s]\n",
            "2018-04-17: 100%|██████████| 323/323 [01:01<00:00,  5.26it/s]\n",
            "2018-04-18: 100%|██████████| 323/323 [01:01<00:00,  5.28it/s]\n",
            "2018-04-19: 100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n",
            "2018-04-20: 100%|██████████| 297/297 [00:55<00:00,  5.31it/s]\n",
            "2018-04-21: 100%|██████████| 297/297 [00:55<00:00,  5.31it/s]\n",
            "2018-04-22: 100%|██████████| 297/297 [00:56<00:00,  5.28it/s]\n",
            "2018-04-23: 100%|██████████| 297/297 [00:56<00:00,  5.28it/s]\n",
            "2018-04-24: 100%|██████████| 297/297 [00:56<00:00,  5.30it/s]\n",
            "2018-04-25: 100%|██████████| 297/297 [00:56<00:00,  5.28it/s]\n",
            "2018-04-26: 100%|██████████| 297/297 [00:56<00:00,  5.26it/s]\n",
            "2018-04-27: 100%|██████████| 297/297 [00:55<00:00,  5.31it/s]\n",
            "2018-04-28: 100%|██████████| 297/297 [00:55<00:00,  5.31it/s]\n",
            "2018-04-29: 100%|██████████| 297/297 [00:55<00:00,  5.31it/s]\n",
            "2018-04-30: 100%|██████████| 22/22 [00:04<00:00,  5.31it/s]\n",
            "2018-05-01: 100%|██████████| 249/249 [00:47<00:00,  5.26it/s]\n",
            "2018-05-02: 100%|██████████| 249/249 [00:47<00:00,  5.25it/s]\n",
            "2018-05-03: 100%|██████████| 249/249 [00:47<00:00,  5.24it/s]\n",
            "2018-05-04: 100%|██████████| 249/249 [00:47<00:00,  5.23it/s]\n",
            "2018-05-05: 100%|██████████| 249/249 [00:47<00:00,  5.24it/s]\n",
            "2018-05-06: 100%|██████████| 249/249 [00:47<00:00,  5.24it/s]\n",
            "2018-05-07: 100%|██████████| 249/249 [00:47<00:00,  5.26it/s]\n",
            "2018-05-08: 100%|██████████| 249/249 [00:47<00:00,  5.26it/s]\n",
            "2018-05-09: 100%|██████████| 249/249 [00:47<00:00,  5.23it/s]\n",
            "2018-05-10: 100%|██████████| 296/296 [00:55<00:00,  5.33it/s]\n",
            "2018-05-11: 100%|██████████| 296/296 [00:55<00:00,  5.32it/s]\n",
            "2018-05-12: 100%|██████████| 296/296 [00:55<00:00,  5.33it/s]\n",
            "2018-05-13: 100%|██████████| 296/296 [00:55<00:00,  5.32it/s]\n",
            "2018-05-14: 100%|██████████| 296/296 [00:55<00:00,  5.32it/s]\n",
            "2018-05-15: 100%|██████████| 296/296 [00:55<00:00,  5.32it/s]\n",
            "2018-05-16: 100%|██████████| 296/296 [00:55<00:00,  5.32it/s]\n",
            "2018-05-17: 100%|██████████| 296/296 [00:55<00:00,  5.32it/s]\n",
            "2018-05-18: 100%|██████████| 296/296 [00:55<00:00,  5.33it/s]\n",
            "2018-05-19: 100%|██████████| 296/296 [00:55<00:00,  5.31it/s]\n",
            "2018-05-20: 100%|██████████| 282/282 [00:52<00:00,  5.33it/s]\n",
            "2018-05-21: 100%|██████████| 282/282 [00:52<00:00,  5.33it/s]\n",
            "2018-05-22: 100%|██████████| 282/282 [00:52<00:00,  5.33it/s]\n",
            "2018-05-23: 100%|██████████| 282/282 [00:52<00:00,  5.35it/s]\n",
            "2018-05-24: 100%|██████████| 282/282 [00:52<00:00,  5.35it/s]\n",
            "2018-05-25: 100%|██████████| 282/282 [00:52<00:00,  5.34it/s]\n",
            "2018-05-26: 100%|██████████| 282/282 [00:53<00:00,  5.32it/s]\n",
            "2018-05-27: 100%|██████████| 282/282 [00:53<00:00,  5.32it/s]\n",
            "2018-05-28: 100%|██████████| 282/282 [00:52<00:00,  5.32it/s]\n",
            "2018-05-29: 100%|██████████| 282/282 [00:53<00:00,  5.32it/s]\n",
            "2018-05-30: 100%|██████████| 56/56 [00:10<00:00,  5.19it/s]\n",
            "2018-05-31: 100%|██████████| 56/56 [00:10<00:00,  5.12it/s]\n",
            "2018-06-01: 100%|██████████| 225/225 [00:41<00:00,  5.48it/s]\n",
            "2018-06-02: 100%|██████████| 225/225 [00:41<00:00,  5.48it/s]\n",
            "2018-06-03: 100%|██████████| 225/225 [00:41<00:00,  5.48it/s]\n",
            "2018-06-04: 100%|██████████| 225/225 [00:41<00:00,  5.48it/s]\n",
            "2018-06-05: 100%|██████████| 225/225 [00:41<00:00,  5.48it/s]\n",
            "2018-06-06: 100%|██████████| 225/225 [00:41<00:00,  5.48it/s]\n",
            "2018-06-07: 100%|██████████| 225/225 [00:41<00:00,  5.48it/s]\n",
            "2018-06-08: 100%|██████████| 225/225 [00:41<00:00,  5.47it/s]\n",
            "2018-06-09: 100%|██████████| 225/225 [00:41<00:00,  5.47it/s]\n",
            "2018-06-10: 100%|██████████| 257/257 [00:46<00:00,  5.54it/s]\n",
            "2018-06-11: 100%|██████████| 257/257 [00:46<00:00,  5.55it/s]\n",
            "2018-06-12: 100%|██████████| 257/257 [00:46<00:00,  5.55it/s]\n",
            "2018-06-13: 100%|██████████| 257/257 [00:46<00:00,  5.54it/s]\n",
            "2018-06-14: 100%|██████████| 257/257 [00:46<00:00,  5.57it/s]\n",
            "2018-06-15: 100%|██████████| 257/257 [00:46<00:00,  5.57it/s]\n",
            "2018-06-16: 100%|██████████| 257/257 [00:46<00:00,  5.58it/s]\n",
            "2018-06-17: 100%|██████████| 257/257 [00:46<00:00,  5.56it/s]\n",
            "2018-06-18: 100%|██████████| 257/257 [00:46<00:00,  5.58it/s]\n",
            "2018-06-19: 100%|██████████| 257/257 [00:46<00:00,  5.58it/s]\n",
            "2018-06-20: 100%|██████████| 242/242 [00:42<00:00,  5.75it/s]\n",
            "2018-06-21: 100%|██████████| 242/242 [00:42<00:00,  5.75it/s]\n",
            "2018-06-22: 100%|██████████| 242/242 [00:42<00:00,  5.76it/s]\n",
            "2018-06-23: 100%|██████████| 242/242 [00:42<00:00,  5.75it/s]\n",
            "2018-06-24: 100%|██████████| 242/242 [00:42<00:00,  5.75it/s]\n",
            "2018-06-25: 100%|██████████| 242/242 [00:42<00:00,  5.73it/s]\n",
            "2018-06-26: 100%|██████████| 242/242 [00:42<00:00,  5.75it/s]\n",
            "2018-06-27: 100%|██████████| 242/242 [00:42<00:00,  5.76it/s]\n",
            "2018-06-28: 100%|██████████| 242/242 [00:42<00:00,  5.76it/s]\n",
            "2018-06-29: 100%|██████████| 242/242 [00:42<00:00,  5.75it/s]\n",
            "2018-06-30: 100%|██████████| 22/22 [00:03<00:00,  5.67it/s]\n",
            "2018-07-01: 100%|██████████| 194/194 [00:33<00:00,  5.76it/s]\n",
            "2018-07-02: 100%|██████████| 194/194 [00:33<00:00,  5.76it/s]\n",
            "2018-07-03: 100%|██████████| 194/194 [00:33<00:00,  5.76it/s]\n",
            "2018-07-04: 100%|██████████| 194/194 [00:33<00:00,  5.76it/s]\n",
            "2018-07-05: 100%|██████████| 194/194 [00:33<00:00,  5.77it/s]\n",
            "2018-07-06: 100%|██████████| 194/194 [00:33<00:00,  5.76it/s]\n",
            "2018-07-07: 100%|██████████| 194/194 [00:33<00:00,  5.76it/s]\n",
            "2018-07-08: 100%|██████████| 194/194 [00:33<00:00,  5.76it/s]\n",
            "2018-07-09: 100%|██████████| 194/194 [00:33<00:00,  5.77it/s]\n",
            "2018-07-10: 100%|██████████| 234/234 [00:42<00:00,  5.47it/s]\n",
            "2018-07-11: 100%|██████████| 234/234 [00:42<00:00,  5.49it/s]\n",
            "2018-07-12: 100%|██████████| 234/234 [00:42<00:00,  5.49it/s]\n",
            "2018-07-13: 100%|██████████| 234/234 [00:42<00:00,  5.50it/s]\n",
            "2018-07-14: 100%|██████████| 234/234 [00:42<00:00,  5.50it/s]\n",
            "2018-07-15: 100%|██████████| 234/234 [00:42<00:00,  5.49it/s]\n",
            "2018-07-16: 100%|██████████| 234/234 [00:42<00:00,  5.50it/s]\n",
            "2018-07-17: 100%|██████████| 234/234 [00:42<00:00,  5.49it/s]\n",
            "2018-07-18: 100%|██████████| 234/234 [00:42<00:00,  5.49it/s]\n",
            "2018-07-19: 100%|██████████| 234/234 [00:42<00:00,  5.49it/s]\n",
            "2018-07-20: 100%|██████████| 233/233 [00:42<00:00,  5.50it/s]\n",
            "2018-07-21: 100%|██████████| 233/233 [00:42<00:00,  5.49it/s]\n",
            "2018-07-22: 100%|██████████| 233/233 [00:42<00:00,  5.45it/s]\n",
            "2018-07-23: 100%|██████████| 233/233 [00:42<00:00,  5.49it/s]\n",
            "2018-07-24: 100%|██████████| 233/233 [00:42<00:00,  5.48it/s]\n",
            "2018-07-25: 100%|██████████| 233/233 [00:42<00:00,  5.51it/s]\n",
            "2018-07-26: 100%|██████████| 233/233 [00:42<00:00,  5.51it/s]\n",
            "2018-07-27: 100%|██████████| 233/233 [00:42<00:00,  5.51it/s]\n",
            "2018-07-28: 100%|██████████| 233/233 [00:42<00:00,  5.51it/s]\n",
            "2018-07-29: 100%|██████████| 233/233 [00:42<00:00,  5.51it/s]\n",
            "2018-07-30: 100%|██████████| 50/50 [00:09<00:00,  5.43it/s]\n",
            "2018-07-31: 100%|██████████| 50/50 [00:09<00:00,  5.43it/s]\n",
            "2018-08-01: 100%|██████████| 209/209 [00:37<00:00,  5.50it/s]\n",
            "2018-08-02: 100%|██████████| 209/209 [00:37<00:00,  5.51it/s]\n",
            "2018-08-03: 100%|██████████| 209/209 [00:37<00:00,  5.51it/s]\n",
            "2018-08-04: 100%|██████████| 209/209 [00:37<00:00,  5.51it/s]\n",
            "2018-08-05: 100%|██████████| 209/209 [00:38<00:00,  5.48it/s]\n",
            "2018-08-06: 100%|██████████| 209/209 [00:37<00:00,  5.51it/s]\n",
            "2018-08-07: 100%|██████████| 209/209 [00:37<00:00,  5.51it/s]\n",
            "2018-08-08: 100%|██████████| 209/209 [00:37<00:00,  5.51it/s]\n",
            "2018-08-09: 100%|██████████| 209/209 [00:37<00:00,  5.51it/s]\n",
            "2018-08-10: 100%|██████████| 214/214 [00:38<00:00,  5.51it/s]\n",
            "2018-08-11: 100%|██████████| 214/214 [00:38<00:00,  5.51it/s]\n",
            "2018-08-12: 100%|██████████| 214/214 [00:38<00:00,  5.51it/s]\n",
            "2018-08-13: 100%|██████████| 214/214 [00:38<00:00,  5.51it/s]\n",
            "2018-08-14: 100%|██████████| 214/214 [00:38<00:00,  5.51it/s]\n",
            "2018-08-15: 100%|██████████| 214/214 [00:38<00:00,  5.51it/s]\n",
            "2018-08-16: 100%|██████████| 214/214 [00:38<00:00,  5.51it/s]\n",
            "2018-08-17: 100%|██████████| 214/214 [00:38<00:00,  5.49it/s]\n",
            "2018-08-18: 100%|██████████| 214/214 [00:38<00:00,  5.50it/s]\n",
            "2018-08-19: 100%|██████████| 214/214 [00:39<00:00,  5.47it/s]\n",
            "2018-08-20: 100%|██████████| 205/205 [00:37<00:00,  5.43it/s]\n",
            "2018-08-21:  51%|█████     | 104/205 [00:19<00:20,  5.00it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rMrDk_sZP1J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw-Y07gDFAdL"
      },
      "source": [
        "!ls ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xu48n3pFTVE"
      },
      "source": [
        "# !rm -r ../data/bitcoin_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eTaM3NyDd0_V"
      },
      "source": [
        "print(results_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z47FRon4Vml"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NENL4_BtZNXw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}