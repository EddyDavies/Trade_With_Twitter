{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer Inference",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EddyDavies/Trade_With_Twitter/blob/main/ipynb/Pipeline_Transformer_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpL2eUlTTzPn",
        "outputId": "3d771372-b931-437f-c7ec-98445e8c1276"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    drive.mount('/content/drive')\n",
        "except ModuleNotFoundError:\n",
        "    IN_COLAB = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mglHXkp5lJJT"
      },
      "source": [
        "Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOuq2MqzlRPG"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssZFeZ-wlbM9"
      },
      "source": [
        "Check TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybKB8RWgld3-"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf-u-YRelOxj"
      },
      "source": [
        "Check Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1_tNatVlHk1",
        "outputId": "e083a344-d7f1-47c1-8370-adb98510a14c"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JQMNNgb3ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9265d33d-ccc0-40c4-cb9c-2659e5ca8096"
      },
      "source": [
        "!git clone https://github.com/EddyDavies/Trade_With_Twitter.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Trade_With_Twitter'...\n",
            "remote: Enumerating objects: 379, done.\u001b[K\n",
            "remote: Counting objects: 100% (379/379), done.\u001b[K\n",
            "remote: Compressing objects: 100% (257/257), done.\u001b[K\n",
            "remote: Total 379 (delta 218), reused 252 (delta 115), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (379/379), 90.40 KiB | 1.19 MiB/s, done.\n",
            "Resolving deltas: 100% (218/218), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpKovQEbHkgm",
        "outputId": "e2a2a69d-1f71-4295-8401-71d4c875a98c"
      },
      "source": [
        "!ls ../"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t datalab  home\t lib64\topt\t    root  srv\t\t     tmp    var\n",
            "boot\t dev\t  lib\t media\tproc\t    run   sys\t\t     tools\n",
            "content  etc\t  lib32  mnt\tpython-apt  sbin  tensorflow-1.15.2  usr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2coR1uRMHkbc",
        "outputId": "acab8365-22a2-4a38-e83e-0d1e78182e3c"
      },
      "source": [
        "%cd Trade_With_Twitter/src\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Trade_With_Twitter/src\n",
            "bert_farm.ipynb  decorators.py\tsentiment  utils.py\n",
            "bert_farm.py\t prices\t\ttwitter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvQ9fTwdr2QH"
      },
      "source": [
        "!pip install -r ../requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5ii2NiXAUZF"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import get_date_array, get_month_array\n",
        "from sentiment.inference import to_dict_of_lists, get_paths"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD1CfxrbBfxf"
      },
      "source": [
        "# 10% before \"2017-09-19\" and 50% after\n",
        "# dates_range = (\"2017-01-01\", \"2021-06-20\")\n",
        "dates_range = (\"2017-09-19\", \"2021-06-20\")\n",
        "months_range = [\"Jan 17\", \"Jun 21\"]\n",
        "\n",
        "months = get_month_array(months_range)\n",
        "dates = get_date_array(dates_range)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPAHsTMfMtNg"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOrhaJXbbH-r"
      },
      "source": [
        "# Create class for data preparation\n",
        "class SimpleDataset:\n",
        "    def __init__(self, tokenized_texts):\n",
        "        self.tokenized_texts = tokenized_texts\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_texts[\"input_ids\"])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAUgIFIPpoA5"
      },
      "source": [
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer, Trainer\n",
        "\n",
        "model_name = \"siebert/sentiment-roberta-large-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "trainer = Trainer(model=model)  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4oIAqHbzR5"
      },
      "source": [
        "tokenizer = tokenizer\n",
        "model = model\n",
        "\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpZZvre_wMcY"
      },
      "source": [
        "if IN_COLAB:\n",
        "    source, results_folder = get_paths(data_folder='../../drive/MyDrive/ColabData', model_name=model_name)\n",
        "else:\n",
        "    source, results_folder = get_paths(model_name=model_name)\n",
        "results_folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_QvwkNhceKA"
      },
      "source": [
        "sentiment_analysis = pipeline(\"sentiment-analysis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CPgRTRM_IKn"
      },
      "source": [
        "from sentiment.inference import get_tweets, get_sentiments, save_sentiments\n",
        "from sentiment.utils import check_last_day\n",
        "\n",
        "for date in dates:\n",
        "    ids, tweets = get_tweets(date, source)\n",
        "\n",
        "    percentage_per_chunk = 50\n",
        "    save_every = 2000\n",
        "    results = get_sentiments(date, tweets, ids, results_folder,\n",
        "                              sentiment_analysis=sentiment_analysis,\n",
        "                              save_every=save_every,\n",
        "                              percentage_per_chunk=percentage_per_chunk)\n",
        "\n",
        "    save_sentiments(ids, tweets, results_folder, date)\n",
        "    check_last_day(results_folder, date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rMrDk_sZP1J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw-Y07gDFAdL"
      },
      "source": [
        "!ls ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xu48n3pFTVE"
      },
      "source": [
        "# !rm -r ../data/bitcoin_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eTaM3NyDd0_V"
      },
      "source": [
        "print(results_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z47FRon4Vml"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NENL4_BtZNXw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}